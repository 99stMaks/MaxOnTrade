# -*- coding: utf-8 -*-
"""–±–æ—Ç —Å –≥—Ä–æ–≥–∞ –ø–æ —Å–º–∞—Ä—Ç –º–∞–Ω–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π  .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v_A0e-x9tT-JeGcVcyfjyXKhEpy2kFGj
"""

pip install pandas numpy requests telebot joblib mplfinance matplotlib scikit-learn websocket-client

import pandas as pd
import numpy as np
import requests
import time
import datetime
import io
import os
import telebot
import joblib
import mplfinance as mpf
import matplotlib.pyplot as plt
import threading
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import logging
import hashlib
import websocket
import json
from collections import defaultdict

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("bot.log", mode='a'),
        logging.StreamHandler()
    ]
)

# Telegram
TELEGRAM_BOT_TOKEN = "8147569970:AAHaZN_h_pnLtsm7cJcvVGPN7ZYEqN7Snos"
TELEGRAM_CHAT_ID = "1300485054"
bot = telebot.TeleBot(TELEGRAM_BOT_TOKEN)

signal_tracking = []
DEBUG_MODE = True
MODEL_PATH = "signal_classifier.joblib"
SCALER_PATH = "scaler.joblib"
DATA_PATH = "signal_data.csv"
data_lock = threading.Lock()

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π
kline_data_m15 = defaultdict(lambda: pd.DataFrame(columns=["timestamp", "open", "high", "low", "close", "volume", "symbol"]))
kline_data_h1 = defaultdict(lambda: pd.DataFrame(columns=["timestamp", "open", "high", "low", "close", "volume", "symbol"]))
kline_data_lock = threading.Lock()

# WebSocket –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è MEXC
WEBSOCKET_URL = "wss://wbs.mexc.com/ws"
PING_INTERVAL = 15

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
scaler = StandardScaler()
model = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3)

if os.path.exists(MODEL_PATH) and os.path.exists(SCALER_PATH):
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    logging.info("–ú–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–æ–≤")
else:
    feature_columns = [
        'rsi', 'atr', 'volume_ratio', 'fib_236', 'fib_5', 'fib_786', 'trend_line', 'ema_diff', 'adx'
    ]
    dummy_data = np.zeros((2, len(feature_columns)))
    dummy_data[1, 0] = 1
    dummy_labels = [0, 1]
    dummy_df = pd.DataFrame(dummy_data, columns=feature_columns)
    scaler.fit(dummy_df)
    model.fit(scaler.transform(dummy_df), dummy_labels)
    logging.info("–ú–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å —Ñ–∏–∫—Ç–∏–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
if os.path.exists(DATA_PATH):
    try:
        data_df = pd.read_csv(DATA_PATH)
        feature_columns = [
            'rsi', 'atr', 'volume_ratio', 'fib_236', 'fib_5', 'fib_786', 'trend_line', 'ema_diff', 'adx'
        ]
        if not data_df.empty and all(col in data_df.columns for col in feature_columns):
            data_df = data_df.dropna(subset=feature_columns + ['result'])
            data_df = data_df[data_df['result'] != -1]
            if not data_df.empty:
                features = data_df[feature_columns]
                labels = data_df['result'].astype(int)
                scaler.fit(features)
                model.partial_fit(scaler.transform(features), labels, classes=[0, 1])
                logging.info("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ signal_data.csv")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ: {e}")

CRYPTO_PAIRS = [
    "BTCUSDT", "ETHUSDT", "XRPUSDT", "BNBUSDT", "SOLUSDT", "TRXUSDT", "DOGEUSDT",
    "AVAXUSDT", "ADAUSDT", "LINKUSDT", "TONUSDT", "XLMUSDT", "SUIUSDT", "LTCUSDT",
    "DOTUSDT", "XMRUSDT", "UNIUSDT", "APTUSDT", "MNTUSDT", "ETCUSDT", "AAVEUSDT",
    "ATOMUSDT", "ENAUSDT"
]

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–¥–µ–ª–æ–∫
TRADE_HISTORY_PATH = "trade_history.csv"
trade_history_lock = threading.Lock()

trade_history_columns = [
    'symbol', 'direction', 'entry_price', 'exit_price', 'profit_pct',
    'sl_price', 'tp_price', 'open_time', 'close_time', 'duration_sec'
]
if os.path.exists(TRADE_HISTORY_PATH):
    trade_history = pd.read_csv(TRADE_HISTORY_PATH, parse_dates=['close_time'])
else:
    trade_history = pd.DataFrame(columns=trade_history_columns)
    trade_history['entry_price'] = trade_history['entry_price'].astype(float, errors='ignore')
    trade_history['exit_price'] = trade_history['exit_price'].astype(float, errors='ignore')
    trade_history['profit_pct'] = trade_history['profit_pct'].astype(float, errors='ignore')
    trade_history['sl_price'] = trade_history['sl_price'].astype(float, errors='ignore')
    trade_history['tp_price'] = trade_history['tp_price'].astype(float, errors='ignore')
    trade_history['duration_sec'] = trade_history['duration_sec'].astype(float, errors='ignore')

# –ö—ç—à –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
active_signals_cache = {}
cache_lock = threading.Lock()
SIGNAL_CACHE_TTL = 2 * 60 * 60

# –ö—ç—à –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
sent_signals_cache = {}
SENT_SIGNAL_TTL = 5 * 60  # 5 –º–∏–Ω—É—Ç

def save_trade_history():
    with trade_history_lock:
        trade_history.to_csv(TRADE_HISTORY_PATH, index=False)

def add_trade_to_history(signal):
    global trade_history
    with trade_history_lock:
        duration = (signal.close_time - signal.open_time).total_seconds() if signal.close_time and signal.open_time else None
        profit_pct = signal.profit
        new_row = {
            'symbol': signal.symbol,
            'direction': signal.direction,
            'entry_price': signal.entry,
            'exit_price': signal.close_price,
            'profit_pct': profit_pct,
            'sl_price': signal.sl,
            'tp_price': signal.tps[0] if signal.tps else None,
            'open_time': signal.open_time,
            'close_time': signal.close_time,
            'duration_sec': duration
        }
        new_df = pd.DataFrame([new_row], columns=trade_history.columns)
        critical_columns = ['entry_price', 'profit_pct', 'sl_price']
        new_df = new_df.dropna(subset=critical_columns)
        if not new_df.empty:
            trade_history = pd.concat([trade_history, new_df], ignore_index=True)
            trade_history[critical_columns] = trade_history[critical_columns].astype(float)
            save_trade_history()
            logging.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ —Å–¥–µ–ª–∫–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é: {signal.symbol}, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {signal.direction}, –ø—Ä–∏–±—ã–ª—å: {profit_pct:.2f}%")
        else:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Å–¥–µ–ª–∫—É –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è {signal.symbol}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")

# WebSocket
def on_message(ws, message):
    try:
        data = json.loads(message)
        if "c" not in data or "d" not in data:
            logging.debug(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π: {message}")
            return
        channel = data["c"]
        if "k" not in data["d"]:
            logging.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'k' –≤ data['d']: {message}")
            return
        kline = data["d"]["k"]
        symbol = data["s"]
        required_fields = ["i", "t", "o", "h", "l", "c", "v"]
        missing_fields = [field for field in required_fields if field not in kline or kline[field] is None]
        if missing_fields:
            logging.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ WebSocket, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è: {missing_fields}, —Å–æ–æ–±—â–µ–Ω–∏–µ: {message}")
            return
        interval = kline["i"]
        timestamp = pd.to_datetime(kline["t"], unit="s")
        is_closed = "T" in kline and kline["T"] is not None
        if not is_closed:
            logging.debug(f"–°–≤–µ—á–∞ –¥–ª—è {symbol} ({interval}) –µ—â—ë –Ω–µ –∑–∞–∫—Ä—ã—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return
        try:
            candle = {
                "timestamp": timestamp,
                "open": float(kline["o"]),
                "high": float(kline["h"]),
                "low": float(kline["l"]),
                "close": float(kline["c"]),
                "volume": float(kline["v"]),
                "symbol": symbol
            }
        except (ValueError, TypeError) as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–∏ –¥–ª—è {symbol} ({interval}): {e}, kline: {kline}")
            return
        with kline_data_lock:
            if interval == "Min15":
                data_store = kline_data_m15
            elif interval == "60m":
                data_store = kline_data_h1
            else:
                logging.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª {interval}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                return
            df = data_store[symbol]
            if not df.empty and timestamp in df["timestamp"].values:
                idx = df[df["timestamp"] == timestamp].index[0]
                for key, value in candle.items():
                    df.at[idx, key] = value
            else:
                new_df = pd.DataFrame([candle], columns=df.columns)
                if df.empty:
                    data_store[symbol] = new_df
                else:
                    data_store[symbol] = pd.concat([df, new_df], ignore_index=True)
            max_length = 300 if interval == "Min15" else 50
            if len(data_store[symbol]) > max_length:
                data_store[symbol] = data_store[symbol].iloc[-max_length:]
            logging.info(f"–ü–æ–ª—É—á–µ–Ω–∞ —Å–≤–µ—á–∞ –¥–ª—è {symbol} ({interval}): {candle}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è WebSocket: {e}")
        logging.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ, –≤—ã–∑–≤–∞–≤—à–µ–µ –æ—à–∏–±–∫—É: {message}")

def on_error(ws, error):
    logging.error(f"WebSocket –æ—à–∏–±–∫–∞: {error}")

def on_close(ws, close_status_code, close_msg):
    logging.warning(f"WebSocket –∑–∞–∫—Ä—ã—Ç: {close_status_code} - {close_msg}")
    delay = 10
    for attempt in range(5):
        logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è {attempt + 1}/5 —á–µ—Ä–µ–∑ {delay} —Å–µ–∫—É–Ω–¥")
        time.sleep(delay)
        try:
            start_websocket()
            break
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            delay *= 2

def on_open(ws):
    logging.info("WebSocket —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –æ—Ç–∫—Ä—ã—Ç–æ")
    for symbol in CRYPTO_PAIRS:
        subscription_m15 = {
            "method": "SUBSCRIPTION",
            "params": [f"spot@public.kline.v3.api@{symbol}@Min15"]
        }
        ws.send(json.dumps(subscription_m15))
        logging.info(f"–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ {symbol} (15m)")
        subscription_h1 = {
            "method": "SUBSCRIPTION",
            "params": [f"spot@public.kline.v3.api@{symbol}@60m"]
        }
        ws.send(json.dumps(subscription_h1))
        logging.info(f"–ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ {symbol} (1h)")
    def ping(ws):
        while ws.sock and ws.sock.connected:
            try:
                ws.send(json.dumps({"method": "PING"}))
                logging.debug("–û—Ç–ø—Ä–∞–≤–ª–µ–Ω PING")
                time.sleep(PING_INTERVAL)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ PING: {e}")
                break
    threading.Thread(target=ping, args=(ws,), daemon=True).start()

def start_websocket():
    ws = websocket.WebSocketApp(
        WEBSOCKET_URL,
        on_open=on_open,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close
    )
    ws.run_forever()

# REST API
def get_session():
    session = requests.Session()
    retries = Retry(
        total=5,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"]
    )
    session.mount("https://", HTTPAdapter(max_retries=retries))
    return session

def get_klines(symbol, interval="15m", limit=300):
    try:
        session = get_session()
        url = "https://api.mexc.com/api/v3/klines"
        params = {"symbol": symbol, "interval": interval, "limit": limit}
        res = session.get(url, params=params, timeout=15)
        res.raise_for_status()
        data = res.json()
        if DEBUG_MODE:
            logging.debug(f"API –æ—Ç–≤–µ—Ç –¥–ª—è {symbol} ({interval}): {data[:2]}")
        if not data or not isinstance(data, list):
            raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç API –¥–ª—è {symbol}: {data}")
        df = pd.DataFrame(data)[[0, 1, 2, 3, 4, 5]]
        df.columns = ["timestamp", "open", "high", "low", "close", "volume"]
        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms")
        for col in ["open", "high", "low", "close", "volume"]:
            df[col] = df[col].astype(float)
        df["symbol"] = symbol
        save_klines(symbol, df, interval)
        return df
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ API –¥–ª—è {symbol} ({interval}): {e}")
        try:
            logging.debug(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {res.text}")
        except:
            pass
        cached_path = f"klines_{symbol}_{interval}.csv"
        if os.path.exists(cached_path):
            logging.info(f"–ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} ({interval})")
            return pd.read_csv(cached_path)
        return None

def save_klines(symbol, df, interval):
    try:
        df.to_csv(f"klines_{symbol}_{interval}.csv", index=False)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞ –¥–ª—è {symbol} ({interval}): {e}")

def init_kline_data():
    for symbol in CRYPTO_PAIRS:
        df_m15 = get_klines(symbol, "15m", 300)
        if df_m15 is not None:
            with kline_data_lock:
                kline_data_m15[symbol] = df_m15
            logging.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} (15m): {len(df_m15)} —Å–≤–µ—á–µ–π")
        else:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} (15m)")
        df_h1 = get_klines(symbol, "60m", 50)
        if df_h1 is not None:
            with kline_data_lock:
                kline_data_h1[symbol] = df_h1
            logging.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} (1h): {len(df_h1)} —Å–≤–µ—á–µ–π")
        else:
            logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} (1h)")
        time.sleep(1)

def get_m15_klines(symbol):
    with kline_data_lock:
        if symbol in kline_data_m15 and not kline_data_m15[symbol].empty:
            logging.debug(f"–í–æ–∑–≤—Ä–∞—â–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} (15m): {len(kline_data_m15[symbol])} —Å–≤–µ—á–µ–π")
            return kline_data_m15[symbol].copy()
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} (15m)")
        return None

def get_h1_klines(symbol):
    with kline_data_lock:
        if symbol in kline_data_h1 and not kline_data_h1[symbol].empty:
            logging.debug(f"–í–æ–∑–≤—Ä–∞—â–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} (1h): {len(kline_data_h1[symbol])} —Å–≤–µ—á–µ–π")
            return kline_data_h1[symbol].copy()
        logging.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} (1h)")
        return None

# –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
SENSITIVITY = 20
TP_LEVELS = [1.0, 2.0, 3.0, 4.0]
TP_SIZES = [0.4, 0.3, 0.2, 0.1]
RISK_PERCENT = 1.0

# Twin Range Filter —Ñ—É–Ω–∫—Ü–∏–∏
def smoothrng(df, period, multiplier):
    """
    –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (–∞–Ω–∞–ª–æ–≥ smoothrng –∏–∑ Pine Script).
    df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π 'close'
    period: –ø–µ—Ä–∏–æ–¥ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è (per1 –∏–ª–∏ per2)
    multiplier: –º–Ω–æ–∂–∏—Ç–µ–ª—å (mult1 –∏–ª–∏ mult2)
    """
    # –†–∞—Å—á—ë—Ç wper = t * 2 - 1
    wper = period * 2 - 1

    # avrng = ema(abs(x - x[1]), t)
    price_diff = df['close'].diff().abs()
    avrng = price_diff.ewm(span=period, adjust=False).mean()

    # smoothrng = ema(avrng, wper) * m
    smoothrng = avrng.ewm(span=wper, adjust=False).mean() * multiplier
    return smoothrng

def rngfilt(df, smrng):
    """
    –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ (–∞–Ω–∞–ª–æ–≥ rngfilt –∏–∑ Pine Script).
    df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–æ–π 'close'
    smrng: —Å–≥–ª–∞–∂–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω (Series)
    """
    source = df['close']
    filt = source.copy()

    for i in range(1, len(source)):
        prev_filt = filt.iloc[i-1] if not pd.isna(filt.iloc[i-1]) else source.iloc[i-1]
        if source.iloc[i] > prev_filt:
            if source.iloc[i] - smrng.iloc[i] < prev_filt:
                filt.iloc[i] = prev_filt
            else:
                filt.iloc[i] = source.iloc[i] - smrng.iloc[i]
        else:
            if source.iloc[i] + smrng.iloc[i] > prev_filt:
                filt.iloc[i] = prev_filt
            else:
                filt.iloc[i] = source.iloc[i] + smrng.iloc[i]

    return filt

def calculate_twin_range_filter(df, per1=27, mult1=1.6, per2=55, mult2=2.0):
    """
    –ü–æ–ª–Ω—ã–π —Ä–∞—Å—á—ë—Ç Twin Range Filter.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–π —Ü–µ–Ω–æ–π, –ø–æ–ª–æ—Å–∞–º–∏ –∏ —É—Å–ª–æ–≤–∏—è–º–∏ —Å–∏–≥–Ω–∞–ª–æ–≤.
    """
    # –®–∞–≥ 1: –†–∞—Å—á—ë—Ç —Å–≥–ª–∞–∂–µ–Ω–Ω—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    smrng1 = smoothrng(df, per1, mult1)
    smrng2 = smoothrng(df, per2, mult2)
    smrng = (smrng1 + smrng2) / 2

    # –®–∞–≥ 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞
    filt = rngfilt(df, smrng)

    # –®–∞–≥ 3: –†–∞—Å—á—ë—Ç upward –∏ downward
    upward = pd.Series(0.0, index=df.index)
    downward = pd.Series(0.0, index=df.index)

    for i in range(1, len(filt)):
        prev_upward = upward.iloc[i-1] if not pd.isna(upward.iloc[i-1]) else 0
        prev_downward = downward.iloc[i-1] if not pd.isna(downward.iloc[i-1]) else 0

        if filt.iloc[i] > filt.iloc[i-1]:
            upward.iloc[i] = prev_upward + 1
            downward.iloc[i] = 0
        elif filt.iloc[i] < filt.iloc[i-1]:
            upward.iloc[i] = 0
            downward.iloc[i] = prev_downward + 1
        else:
            upward.iloc[i] = prev_upward
            downward.iloc[i] = prev_downward

    # –®–∞–≥ 4: –ü–æ–ª–æ—Å—ã
    hband = filt + smrng
    lband = filt - smrng

    # –®–∞–≥ 5: –£—Å–ª–æ–≤–∏—è –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
    source = df['close']
    long_cond = pd.Series(False, index=df.index)
    short_cond = pd.Series(False, index=df.index)

    for i in range(1, len(df)):
        long_cond.iloc[i] = (
            (source.iloc[i] > filt.iloc[i] and source.iloc[i] > source.iloc[i-1] and upward.iloc[i] > 0) or
            (source.iloc[i] > filt.iloc[i] and source.iloc[i] < source.iloc[i-1] and upward.iloc[i] > 0)
        )
        short_cond.iloc[i] = (
            (source.iloc[i] < filt.iloc[i] and source.iloc[i] < source.iloc[i-1] and downward.iloc[i] > 0) or
            (source.iloc[i] < filt.iloc[i] and source.iloc[i] > source.iloc[i-1] and downward.iloc[i] > 0)
        )

    # –®–∞–≥ 6: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —Å–º–µ–Ω—ã —Ç—Ä–µ–Ω–¥–∞ (CondIni)
    cond_ini = pd.Series(0, index=df.index)
    for i in range(1, len(df)):
        if long_cond.iloc[i]:
            cond_ini.iloc[i] = 1
        elif short_cond.iloc[i]:
            cond_ini.iloc[i] = -1
        else:
            cond_ini.iloc[i] = cond_ini.iloc[i-1]

    # –®–∞–≥ 7: –ò—Ç–æ–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã
    long_signal = (long_cond) & (cond_ini.shift(1) == -1)
    short_signal = (short_cond) & (cond_ini.shift(1) == 1)

    return {
        "filt": filt,
        "smrng": smrng,
        "hband": hband,
        "lband": lband,
        "upward": upward,
        "downward": downward,
        "long_signal": long_signal.iloc[-1],
        "short_signal": short_signal.iloc[-1]
    }

# –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
def calculate_fib_levels(df, sensitivity=SENSITIVITY):
    high = df['high'].rolling(sensitivity).max()
    low = df['low'].rolling(sensitivity).min()
    diff = high - low
    return {
        'high': high,
        'low': low,
        '0.236': high - diff * 0.236,
        '0.5': high - diff * 0.5,
        '0.786': high - diff * 0.786
    }

def calculate_poc(df):
    volume_profile = df.groupby('close')['volume'].sum()
    return volume_profile.idxmax() if not volume_profile.empty else None

def calculate_atr(df, period=14):
    high, low, close = df['high'], df['low'], df['close']
    tr1 = high - low
    tr2 = (high - close.shift()).abs()
    tr3 = (low - close.shift()).abs()
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    return tr.rolling(period).mean()

def calculate_rsi(df, period=14):
    delta = df["close"].diff()
    gain = delta.where(delta > 0, 0).rolling(period).mean()
    loss = -delta.where(delta < 0, 0).rolling(period).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

def calculate_adx(df, period=14):
    high, low, close = df['high'], df['low'], df['close']
    plus_dm = high.diff()
    minus_dm = low.diff()
    plus_dm = plus_dm.where((plus_dm > minus_dm) & (plus_dm > 0), 0)
    minus_dm = minus_dm.where((minus_dm > plus_dm) & (minus_dm > 0), 0)
    tr = calculate_atr(df, period)
    plus_di = 100 * (plus_dm.rolling(period).mean() / tr)
    minus_di = 100 * (minus_dm.rolling(period).mean() / tr)
    dx = 100 * ((plus_di - minus_di).abs() / (plus_di + minus_di))
    adx = dx.rolling(period).mean()
    return adx

def calculate_sl(df, entry_price, direction):
    fib = calculate_fib_levels(df)
    atr = calculate_atr(df).iloc[-1]
    atr_ma = calculate_atr(df).rolling(20).mean().iloc[-1]
    atr_multiplier = 1.0 if atr > atr_ma * 1.5 else 0.5
    if direction == 'LONG':
        sl = fib['0.786'].iloc[-1] - atr * atr_multiplier
        return min(sl, entry_price - atr * atr_multiplier)
    else:
        sl = fib['0.236'].iloc[-1] + atr * atr_multiplier
        return max(sl, entry_price + atr * atr_multiplier)

def is_sideways_market(df):
    atr = calculate_atr(df).iloc[-1]
    atr_ma = calculate_atr(df).rolling(20).mean().iloc[-1]
    return atr < atr_ma * 0.3

def check_market_trend(df):
    ema20 = df['close'].ewm(span=20).mean().iloc[-1]
    ema50 = df['close'].ewm(span=50).mean().iloc[-1]
    if ema20 > ema50:
        return "BULLISH"
    elif ema20 < ema50:
        return "BEARISH"
    return "SIDEWAYS"

def check_higher_tf_trend(symbol):
    df = get_h1_klines(symbol)
    if df is None:
        return None
    return check_market_trend(df)

def find_entry_points(df, sym):
    entries = {
        "long_entry": None, "long_tp": None, "long_sl": None, "long_reason": None,
        "short_entry": None, "short_tp": None, "short_sl": None, "short_reason": None,
        "debug_info": [], "additional_info": None,
        "fibonacci": None, "poc": None, "trend_line": None
    }

    current_price = df['close'].iloc[-1]
    fib = calculate_fib_levels(df)
    trend_line = fib['0.5']
    rsi = calculate_rsi(df).iloc[-1]
    adx = calculate_adx(df).iloc[-1]
    atr = calculate_atr(df).iloc[-1]
    atr_ma = calculate_atr(df).rolling(20).mean().iloc[-1]
    volume = df['volume'].iloc[-1]
    volume_ma = df['volume'].rolling(20).mean().iloc[-1]
    volume_ratio = volume / volume_ma if volume_ma != 0 else 1.0

    higher_tf_trend = check_higher_tf_trend(sym)
    market_trend = check_market_trend(df)
    entries["additional_info"] = f"–¢—Ä–µ–Ω–¥ (15m): {market_trend}, –¢—Ä–µ–Ω–¥ (1h): {higher_tf_trend}"
    entries["fibonacci"] = fib
    entries["trend_line"] = trend_line
    entries["poc"] = calculate_poc(df)

    # –§–∏–ª—å—Ç—Ä—ã
    can_trade = True
    reasons = []
    if atr > atr_ma * 2:
        can_trade = False
        reasons.append("–°–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (ATR)")
    if atr <= atr_ma * 0.3:
        can_trade = False
        reasons.append("–ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (ATR)")
    if volume_ratio <= 0.6:
        can_trade = False
        reasons.append("–ù–∏–∑–∫–∏–π –æ–±—ä—ë–º")
    if adx <= 25:
        can_trade = False
        reasons.append("–°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥ (ADX)")

    if not can_trade:
        entries["debug_info"].append(", ".join(reasons))
        return entries

    # –†–∞—Å—á—ë—Ç Twin Range Filter
    trf = calculate_twin_range_filter(df, per1=14, mult1=1.6, per2=34, mult2=2.0)
    trf_long = trf["long_signal"]
    trf_short = trf["short_signal"]

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–¥–∞
    trend_direction = market_trend
    if trend_direction == "SIDEWAYS" and higher_tf_trend:
        trend_direction = higher_tf_trend

    # –£—Å–ª–æ–≤–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ (–∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Å Twin Range Filter)
    can_long = (
        current_price > trend_line.iloc[-1] and
        current_price >= fib['0.236'].iloc[-1] and
        rsi >= 50 and
        trf_long  # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ª–æ–≤–∏–µ Twin Range Filter
    )

    can_short = (
        current_price < trend_line.iloc[-1] and
        current_price <= fib['0.786'].iloc[-1] and
        rsi <= 50 and
        trf_short  # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ª–æ–≤–∏–µ Twin Range Filter
    )

    if can_long and can_short:
        if trend_direction == "BULLISH":
            can_short = False
        elif trend_direction == "BEARISH":
            can_long = False
        else:
            if rsi > 50:
                can_short = False
            else:
                can_long = False

    if can_long:
        entries["long_entry"] = current_price
        entries["long_tp"] = [current_price * (1 + tp / 100) for tp in TP_LEVELS]
        entries["long_sl"] = calculate_sl(df, current_price, 'LONG')
        entries["long_reason"] = (
            f"LONG: –¶–µ–Ω–∞ –≤—ã—à–µ —Ç—Ä–µ–Ω–¥–æ–≤–æ–π –ª–∏–Ω–∏–∏ ({trend_line.iloc[-1]:.4f}) –∏ Fib 0.236 ({fib['0.236'].iloc[-1]:.4f}), "
            f"RSI: {rsi:.2f}, ADX: {adx:.2f}, ATR: {atr:.4f}, Twin Range Filter: Long"
        )
    if can_short:
        entries["short_entry"] = current_price
        entries["short_tp"] = [current_price * (1 - tp / 100) for tp in TP_LEVELS]
        entries["short_sl"] = calculate_sl(df, current_price, 'SHORT')
        entries["short_reason"] = (
            f"SHORT: –¶–µ–Ω–∞ –Ω–∏–∂–µ —Ç—Ä–µ–Ω–¥–æ–≤–æ–π –ª–∏–Ω–∏–∏ ({trend_line.iloc[-1]:.4f}) –∏ Fib 0.786 ({fib['0.786'].iloc[-1]:.4f}), "
            f"RSI: {rsi:.2f}, ADX: {adx:.2f}, ATR: {atr:.4f}, Twin Range Filter: Short"
        )
    if not entries["long_entry"] and not entries["short_entry"]:
        entries["debug_info"].append("–£—Å–ª–æ–≤–∏—è –¥–ª—è –≤—Ö–æ–¥–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã")

    return entries

class Signal:
    def __init__(self, symbol, direction, entry, tps, sl, reason):
        self.symbol = symbol
        self.direction = direction
        self.entry = entry
        self.tps = tps
        self.tp_sizes = TP_SIZES
        self.sl = sl
        self.reason = reason
        self.status = 'open'
        self.open_time = datetime.datetime.utcnow()
        self.close_price = None
        self.profit = 0.0
        self.close_time = None
        self.position_size_left = 1.0
        self.break_even_hit = False
        self.break_even_price = tps[0]

    def update(self, current_price, df):
        if self.status != 'open':
            return self.status

        atr = calculate_atr(df).iloc[-1]
        fib = calculate_fib_levels(df)
        trend_line = fib['0.5'].iloc[-1]

        profit = 0.0
        if self.direction == 'LONG':
            for i, tp in enumerate(self.tps):
                if current_price >= tp and self.position_size_left > 0:
                    size = min(self.tp_sizes[i], self.position_size_left)
                    self.position_size_left -= size
                    profit += (tp - self.entry) / self.entry * 100 * size
                    if i == 0:
                        self.break_even_hit = True
                    if self.position_size_left <= 0:
                        self.status = 'hit_tp'
                        self.close_price = current_price
                        break
            if current_price <= self.sl:
                self.status = 'hit_sl'
                self.close_price = self.sl
                profit -= (self.entry - self.sl) / self.entry * 100 * self.position_size_left
                self.position_size_left = 0
            elif self.break_even_hit and current_price <= self.entry:
                self.status = 'break_even'
                self.close_price = self.entry
                self.position_size_left = 0
            elif current_price <= trend_line:
                self.status = 'trend_change'
                self.close_price = current_price
                profit += (current_price - self.entry) / self.entry * 100 * self.position_size_left
                self.position_size_left = 0
        else:
            for i, tp in enumerate(self.tps):
                if current_price <= tp and self.position_size_left > 0:
                    size = min(self.tp_sizes[i], self.position_size_left)
                    self.position_size_left -= size
                    profit += (self.entry - tp) / self.entry * 100 * size
                    if i == 0:
                        self.break_even_hit = True
                    if self.position_size_left <= 0:
                        self.status = 'hit_tp'
                        self.close_price = current_price
                        break
            if current_price >= self.sl:
                self.status = 'hit_sl'
                self.close_price = self.sl
                profit -= (self.sl - self.entry) / self.entry * 100 * self.position_size_left
                self.position_size_left = 0
            elif self.break_even_hit and current_price >= self.entry:
                self.status = 'break_even'
                self.close_price = self.entry
                self.position_size_left = 0
            elif current_price >= trend_line:
                self.status = 'trend_change'
                self.close_price = current_price
                profit += (self.entry - current_price) / self.entry * 100 * self.position_size_left
                self.position_size_left = 0

        self.profit += profit
        if self.position_size_left <= 0 or self.status != 'open':
            self.close_time = datetime.datetime.utcnow()
            self.status = 'closed'

        return self.status

def save_signal_data(signal, df, entries, result=None):
    try:
        current_price = df['close'].iloc[-1]
        fib = entries.get("fibonacci", {})
        trend_line = entries.get("trend_line", pd.Series()).iloc[-1] if not pd.isna(entries.get("trend_line")) else 0
        features = {
            "rsi": calculate_rsi(df).iloc[-1],
            "atr": calculate_atr(df).iloc[-1],
            "volume_ratio": df['volume'].iloc[-1] / df['volume'].rolling(20).mean().iloc[-1],
            "fib_236": fib.get('0.236', pd.Series()).iloc[-1] if '0.236' in fib else 0,
            "fib_5": fib.get('0.5', pd.Series()).iloc[-1] if '0.5' in fib else 0,
            "fib_786": fib.get('0.786', pd.Series()).iloc[-1] if '0.786' in fib else 0,
            "trend_line": trend_line,
            "ema_diff": df['close'].ewm(span=20).mean().iloc[-1] - df['close'].ewm(span=50).mean().iloc[-1],
            "adx": calculate_adx(df).iloc[-1],
            "result": result if result is not None else -1
        }
        df_features = pd.DataFrame([features])
        with data_lock:
            if os.path.exists(DATA_PATH):
                df_features.to_csv(DATA_PATH, mode='a', header=False, index=False)
            else:
                df_features.to_csv(DATA_PATH, index=False)
        if DEBUG_MODE:
            logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è {signal.symbol} —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º {features['result']}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–∞: {e}")

def predict_signal_success(signal, df, entries):
    try:
        current_price = df['close'].iloc[-1]
        fib = entries.get("fibonacci", {})
        trend_line = entries.get("trend_line", pd.Series()).iloc[-1] if not pd.isna(entries.get("trend_line")) else 0
        features = [
            calculate_rsi(df).iloc[-1],
            calculate_atr(df).iloc[-1],
            df['volume'].iloc[-1] / df['volume'].rolling(20).mean().iloc[-1],
            fib.get('0.236', pd.Series()).iloc[-1] if '0.236' in fib else 0,
            fib.get('0.5', pd.Series()).iloc[-1] if '0.5' in fib else 0,
            fib.get('0.786', pd.Series()).iloc[-1] if '0.786' in fib else 0,
            trend_line,
            df['close'].ewm(span=20).mean().iloc[-1] - df['close'].ewm(span=50).mean().iloc[-1],
            calculate_adx(df).iloc[-1]
        ]
        feature_columns = [
            'rsi', 'atr', 'volume_ratio', 'fib_236', 'fib_5', 'fib_786', 'trend_line', 'ema_diff', 'adx'
        ]
        df_features = pd.DataFrame([features], columns=feature_columns)
        features_scaled = scaler.transform(df_features)
        proba = model.predict_proba(features_scaled)[0][1]
        return proba
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞: {e}")
        return None

def update_model():
    try:
        if not os.path.exists(DATA_PATH):
            return
        with data_lock:
            df = pd.read_csv(DATA_PATH)
        feature_columns = [
            'rsi', 'atr', 'volume_ratio', 'fib_236', 'fib_5', 'fib_786', 'trend_line', 'ema_diff', 'adx'
        ]
        df = df.dropna(subset=feature_columns + ['result'])
        df = df[df['result'] != -1]
        if df.empty:
            return
        X = df[feature_columns]
        y = df['result'].astype(int)
        scaler.fit(X)
        X_scaled = scaler.transform(X)
        model.partial_fit(X_scaled, y, classes=[0, 1])
        joblib.dump(model, MODEL_PATH)
        joblib.dump(scaler, SCALER_PATH)
        logging.info("–ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –æ–Ω–ª–∞–π–Ω")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")

def update_signal_result(signal, result):
    try:
        if not os.path.exists(DATA_PATH):
            return
        with data_lock:
            df = pd.read_csv(DATA_PATH)
            idx = df[df['result'] == -1].index.max()
            if pd.notna(idx):
                df.at[idx, 'result'] = result
                df.to_csv(DATA_PATH, index=False)
                logging.info(f"–û–±–Ω–æ–≤–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–≥–Ω–∞–ª–∞ –¥–ª—è {signal.symbol} –Ω–∞ {result}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å–∏–≥–Ω–∞–ª–∞: {e}")

def calculate_position_size(balance, risk_percent, entry_price, sl_price):
    try:
        risk_amount = balance * (risk_percent / 100)
        stop_loss_distance = abs(entry_price - sl_price)
        if stop_loss_distance == 0:
            return 0
        position_size = risk_amount / stop_loss_distance
        return position_size
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏: {e}")
        return 0

def get_execution_price(symbol, direction):
    return None

def generate_signal_id(symbol, direction, entry_price):
    base_str = f"{symbol}_{direction}_{entry_price:.6f}"
    return hashlib.sha256(base_str.encode()).hexdigest()

def clean_expired_signals():
    now = time.time()
    with cache_lock:
        expired = [sid for sid, ts in active_signals_cache.items() if now - ts > SIGNAL_CACHE_TTL]
        for sid in expired:
            del active_signals_cache[sid]

def send_recommendations(sym, df):
    try:
        clean_expired_signals()
        if is_sideways_market(df):
            logging.info(f"{sym}: –†—ã–Ω–æ–∫ –≤ –±–æ–∫–æ–≤–∏–∫–µ (ATR –Ω–∏–∑–∫–∏–π), —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è")
            return
        entries = find_entry_points(df, sym)
        current_price = df['close'].iloc[-1]
        balance = 1000
        risk_percent = RISK_PERCENT

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —Å–∏–≥–Ω–∞–ª –¥–ª—è —ç—Ç–æ–π –º–æ–Ω–µ—Ç—ã
        now = time.time()
        with cache_lock:
            signal_key = None
            if entries["long_entry"]:
                signal_key = f"{sym}_LONG"
            elif entries["short_entry"]:
                signal_key = f"{sym}_SHORT"

            if signal_key:
                if signal_key in sent_signals_cache:
                    last_sent = sent_signals_cache[signal_key]
                    if now - last_sent < SENT_SIGNAL_TTL:
                        logging.info(f"{sym}: –°–∏–≥–Ω–∞–ª {signal_key} –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        return
                sent_signals_cache[signal_key] = now

        expired = [key for key, ts in sent_signals_cache.items() if now - ts > SENT_SIGNAL_TTL]
        for key in expired:
            del sent_signals_cache[key]

        if entries["long_entry"]:
            signal_id = generate_signal_id(sym, "LONG", entries["long_entry"])
            with cache_lock:
                if signal_id in active_signals_cache:
                    logging.info(f"{sym} LONG —Å–∏–≥–Ω–∞–ª —É–∂–µ –∞–∫—Ç–∏–≤–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    return
                active_signals_cache[signal_id] = time.time()
            entries["long_entry"] = get_execution_price(sym, "LONG") or entries["long_entry"]
            signal = Signal(sym, "LONG", entries["long_entry"], entries["long_tp"], entries["long_sl"], entries["long_reason"])
            prob = predict_signal_success(signal, df, entries)
            if prob is not None:
                signal.reason += f"\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ (ML): {prob*100:.1f}%"
            signal_tracking.append(signal)
            save_signal_data(signal, df, entries)
            logging.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω LONG —Å–∏–≥–Ω–∞–ª –¥–ª—è {sym}")

        if entries["short_entry"]:
            signal_id = generate_signal_id(sym, "SHORT", entries["short_entry"])
            with cache_lock:
                if signal_id in active_signals_cache:
                    logging.info(f"{sym} SHORT —Å–∏–≥–Ω–∞–ª —É–∂–µ –∞–∫—Ç–∏–≤–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    return
                active_signals_cache[signal_id] = time.time()
            entries["short_entry"] = get_execution_price(sym, "SHORT") or entries["short_entry"]
            signal = Signal(sym, "SHORT", entries["short_entry"], entries["short_tp"], entries["short_sl"], entries["short_reason"])
            prob = predict_signal_success(signal, df, entries)
            if prob is not None:
                signal.reason += f"\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ (ML): {prob*100:.1f}%"
            signal_tracking.append(signal)
            save_signal_data(signal, df, entries)
            logging.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω SHORT —Å–∏–≥–Ω–∞–ª –¥–ª—è {sym}")

        if not entries["long_entry"] and not entries["short_entry"]:
            logging.info(f"{sym}: –ù–µ—Ç —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            return

        msg = f"üîä <b>{sym}</b> | –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: {current_price:.4f}\n"
        if entries["long_entry"]:
            position_size = calculate_position_size(balance, risk_percent, entries["long_entry"], entries["long_sl"])
            msg += f"üìà <b>LONG —Å—Ü–µ–Ω–∞—Ä–∏–π:</b>\n"
            msg += f"–í—Ö–æ–¥: {entries['long_entry']:.4f}\n"
            msg += f"TP1: {entries['long_tp'][0]:.4f} ({TP_SIZES[0]*100}%)\n"
            msg += f"TP2: {entries['long_tp'][1]:.4f} ({TP_SIZES[1]*100}%)\n"
            msg += f"TP3: {entries['long_tp'][2]:.4f} ({TP_SIZES[2]*100}%)\n"
            msg += f"TP4: {entries['long_tp'][3]:.4f} ({TP_SIZES[3]*100}%)\n"
            msg += f"SL: {entries['long_sl']:.4f}\n"
            msg += f"POC: {entries['poc']:.4f}\n"
            msg += f"–ü—Ä–∏—á–∏–Ω–∞: {entries['long_reason']}\n"
            msg += f"–†–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: {position_size:.2f} USDT (—Ä–∏—Å–∫ {risk_percent}%)\n"
        if entries["short_entry"]:
            position_size = calculate_position_size(balance, risk_percent, entries["short_entry"], entries["short_sl"])
            msg += f"üìâ <b>SHORT —Å—Ü–µ–Ω–∞—Ä–∏–π:</b>\n"
            msg += f"–í—Ö–æ–¥: {entries['short_entry']:.4f}\n"
            msg += f"TP1: {entries['short_tp'][0]:.4f} ({TP_SIZES[0]*100}%)\n"
            msg += f"TP2: {entries['short_tp'][1]:.4f} ({TP_SIZES[1]*100}%)\n"
            msg += f"TP3: {entries['short_tp'][2]:.4f} ({TP_SIZES[2]*100}%)\n"
            msg += f"TP4: {entries['short_tp'][3]:.4f} ({TP_SIZES[3]*100}%)\n"
            msg += f"SL: {entries['short_sl']:.4f}\n"
            msg += f"POC: {entries['poc']:.4f}\n"
            msg += f"–ü—Ä–∏—á–∏–Ω–∞: {entries['short_reason']}\n"
            msg += f"–†–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: {position_size:.2f} USDT (—Ä–∏—Å–∫ {risk_percent}%)\n"
        if entries["additional_info"]:
            msg += f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: {entries['additional_info']}\n"

        df_plot = df.tail(50).copy()
        df_plot.set_index('timestamp', inplace=True)
        apdict = []
        if entries["fibonacci"]:
            for level, prices in entries["fibonacci"].items():
                if level in ['0.236', '0.5', '0.786']:
                    apdict.append(mpf.make_addplot(
                        [prices.iloc[-1]] * len(df_plot),
                        type='line',
                        linestyle='--',
                        color='purple',
                        alpha=0.5,
                        label=f'Fib {level}'
                    ))
        if entries["trend_line"] is not None:
            apdict.append(mpf.make_addplot(
                [entries["trend_line"].iloc[-1]] * len(df_plot),
                type='line',
                linestyle='-',
                color='blue',
                alpha=0.7,
                label='Trend Line (Fib 0.5)'
            ))
        if entries["poc"]:
            apdict.append(mpf.make_addplot(
                [entries["poc"]] * len(df_plot),
                type='line',
                linestyle='--',
                color='green',
                alpha=0.5,
                label='POC'
            ))

        fig, axlist = mpf.plot(
            df_plot,
            type='candle',
            style='yahoo',
            volume=True,
            figsize=(12, 8),
            addplot=apdict,
            returnfig=True,
            tight_layout=True,
            datetime_format='%H:%M',
            ylabel='Price',
            title=f"{sym} 15m Chart"
        )
        axlist[0].legend()
        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight')
        buf.seek(0)
        plt.close(fig)
        bot.send_photo(TELEGRAM_CHAT_ID, buf, caption=msg, parse_mode="HTML")
        save_klines(sym, df, "15m")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è {sym}: {e}")
        bot.send_message(TELEGRAM_CHAT_ID, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è {sym}: {str(e)}")

def track_signals():
    while True:
        for signal in signal_tracking[:]:
            df = get_m15_klines(signal.symbol)
            if df is None or df.empty:
                continue
            current_price = df['close'].iloc[-1]
            status = signal.update(current_price, df)
            if status == 'closed':
                signal.close_time = datetime.datetime.utcnow()
                add_trade_to_history(signal)
                update_signal_result(signal, 1 if signal.status == 'hit_tp' else 0)
                signal_tracking.remove(signal)
                logging.info(f"–°–∏–≥–Ω–∞–ª {signal.symbol} –∑–∞–∫—Ä—ã—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º {signal.status}")
        time.sleep(60)

def send_periodic_stats():
    while True:
        time.sleep(2 * 60 * 60)
        now = datetime.datetime.utcnow()
        two_hours_ago = now - datetime.timedelta(hours=2)

        with trade_history_lock:
            recent_trades = trade_history[trade_history['close_time'] >= two_hours_ago]
            if recent_trades.empty:
                closed_msg = "–ó–∞–∫—Ä—ã—Ç—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —á–∞—Å–∞ –Ω–µ—Ç.\n"
            else:
                total_trades = len(recent_trades)
                wins = len(recent_trades[recent_trades['profit_pct'] > 0])
                losses = len(recent_trades[recent_trades['profit_pct'] <= 0])
                hit_tp = len(recent_trades[recent_trades['profit_pct'] > 0])
                hit_sl = len(recent_trades[recent_trades['profit_pct'] <= 0])
                win_rate = wins / total_trades * 100 if total_trades > 0 else 0
                avg_profit = recent_trades['profit_pct'].mean() if not recent_trades['profit_pct'].empty else 0.0
                avg_duration = recent_trades['duration_sec'].mean() if not recent_trades['duration_sec'].empty else 0
                avg_duration_str = str(datetime.timedelta(seconds=int(avg_duration))) if avg_duration else "N/A"
                closed_msg = (
                    f"üìä <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–∫—Ä—ã—Ç—ã—Ö —Å–¥–µ–ª–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 —á–∞—Å–∞:</b>\n"
                    f"–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total_trades}\n"
                    f"–î–æ—Å—Ç–∏–≥–ª–∏ TP: {hit_tp}\n"
                    f"–î–æ—Å—Ç–∏–≥–ª–∏ SL: {hit_sl}\n"
                    f"–ü–æ–±–µ–¥: {wins} ({win_rate:.2f}%)\n"
                    f"–ü—Ä–æ–∏–≥—Ä—ã—à–µ–π: {losses}\n"
                    f"–°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫: {avg_profit:.2f}%\n"
                    f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–¥–µ–ª–∫–∏: {avg_duration_str}\n"
                )

        active_signals = []
        with cache_lock:
            active_signals = [signal for signal in signal_tracking if signal.status == 'open']

        if not active_signals:
            active_msg = "–ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–µ—Ç.\n"
        else:
            active_msg = f"üìà <b>–ê–∫—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã:</b>\n"
            for signal in active_signals:
                df = get_m15_klines(signal.symbol)
                if df is None or df.empty:
                    continue
                current_price = df['close'].iloc[-1]
                profit = (current_price - signal.entry) / signal.entry * 100 if signal.direction == 'LONG' else (signal.entry - current_price) / signal.entry * 100
                active_msg += (
                    f"{signal.symbol} ({signal.direction}): –í—Ö–æ–¥: {signal.entry:.4f}, "
                    f"–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: {current_price:.4f}, –ü—Ä–∏–±—ã–ª—å: {profit:.2f}%\n"
                )

        msg = closed_msg + "\n" + active_msg
        bot.send_message(TELEGRAM_CHAT_ID, msg, parse_mode="HTML")

def send_hourly_stats():
    while True:
        time.sleep(3600)
        now = datetime.datetime.utcnow()
        one_hour_ago = now - datetime.timedelta(hours=1)
        with trade_history_lock:
            recent = trade_history[trade_history['close_time'] >= one_hour_ago]
            if recent.empty:
                bot.send_message(TELEGRAM_CHAT_ID, "üìä –ù–µ—Ç —Å–¥–µ–ª–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å.")
                continue
            total = len(recent)
            wins = len(recent[recent['profit_pct'] > 0])
            losses = total - wins
            win_rate = (wins / total) * 100 if total > 0 else 0
            avg_profit = recent['profit_pct'].mean()
            avg_profit = avg_profit if not pd.isna(avg_profit) else 0.0
            msg = (
                f"‚è± <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å:</b>\n"
                f"–°–¥–µ–ª–æ–∫: {total}\n"
                f"–ü–æ–±–µ–¥: {wins} | –ü—Ä–æ–∏–≥—Ä—ã—à–µ–π: {losses}\n"
                f"Win Rate: {win_rate:.2f}%\n"
                f"–°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å: {avg_profit:.2f}%"
            )
            bot.send_message(TELEGRAM_CHAT_ID, msg, parse_mode="HTML")

def main():
    init_kline_data()
    threading.Thread(target=start_websocket, daemon=True).start()
    threading.Thread(target=track_signals, daemon=True).start()
    threading.Thread(target=send_periodic_stats, daemon=True).start()
    threading.Thread(target=send_hourly_stats, daemon=True).start()

    while True:
        for symbol in CRYPTO_PAIRS:
            df = get_m15_klines(symbol)
            if df is None or df.empty:
                continue
            send_recommendations(symbol, df)
        time.sleep(60)

if __name__ == "__main__":
    main()